{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import sinergym\n",
    "from sinergym.utils.wrappers import *\n",
    "from sinergym.utils.constants import RANGES_5ZONE\n",
    "\n",
    "env = gym.make('Eplus-5Zone-hot-discrete-v1')\n",
    "\n",
    "env = NormalizeObservation(\n",
    "    env=env,\n",
    "    ranges=RANGES_5ZONE)\n",
    "\n",
    "env = LoggerWrapper(env=env, flag=True)\n",
    "env = MultiObsWrapper(env=env, n=5, flatten=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hnp.agents import QLearningAgent\n",
    "from hnp.environment import ObservationWrapper\n",
    "\n",
    "env = ObservationWrapper(env, np.array([0, 1, 8, 10]))\n",
    "\n",
    "config = {\n",
    "    \"agent\": {\n",
    "        \"num_episodes\": 500,\n",
    "        \"horizon\": 24,\n",
    "        \"gamma\": 0.99,\n",
    "        \"num_tiles\": 20,\n",
    "        \"initial_epsilon\": 1,\n",
    "        \"epsilon_annealing\": 0.999,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"learning_rate_annealing\": 0.999\n",
    "    }\n",
    "}\n",
    "\n",
    "mask = np.array([0, 0, 0, 0]) # slowly changing observation variable\n",
    "\n",
    "# define agent and then train\n",
    "agent = QLearningAgent(env, config[\"agent\"], mask)\n",
    "agent.train()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hnp.agents import QLearningAgent\n",
    "from hnp.environment import ObservationWrapper, create_env\n",
    "\n",
    "config = {\n",
    "    \"agent\": {\n",
    "        \"num_episodes\": 500,\n",
    "        \"horizon\": 24,\n",
    "        \"gamma\": 0.99,\n",
    "        \"num_tiles\": 20,\n",
    "        \"initial_epsilon\": 1,\n",
    "        \"epsilon_annealing\": 0.999,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"learning_rate_annealing\": 0.999\n",
    "    },\n",
    "    \"env\": {\n",
    "        \"name\": \"Eplus-5Zone-hot-discrete-v1\",\n",
    "        \"normalize\": True,\n",
    "        \"obs_to_keep\": [0, 1, 8, 10],\n",
    "        \"mask\": [0, 0, 0, 0]\n",
    "    }\n",
    "}\n",
    "\n",
    "obs_to_keep = np.array(config[\"env\"][\"obs_to_keep\"])\n",
    "mask = np.array(config[\"env\"][\"mask\"])\n",
    "\n",
    "env = create_env(config[\"env\"])\n",
    "env = ObservationWrapper(env, obs_to_keep)\n",
    "\n",
    "agent = QLearningAgent(\n",
    "    env,\n",
    "    config[\"agent\"],\n",
    "    mask,\n",
    ")\n",
    "agent.train()\n",
    "agent.save_results()\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
